From b694a899c6eec8ab6ced01a8ff0558fe55f9b5ca Mon Sep 17 00:00:00 2001
From: Shantanu Shrivastava <shanshri@amd.com>
Date: Tue, 24 Oct 2023 10:23:49 +0000
Subject: [PATCH] drivers/soc/pensando: kpcimgr driver

kpcimgr driver enables the relocation of the module code to handle
Elba indirect PCIe transactions.

Signed-off-by: David Clear <dclear@amd.com>
Signed-off-by: Shantanu Shrivastava <shanshri@amd.com>
---
 arch/arm64/boot/dts/pensando/elba.dtsi |  11 +
 drivers/soc/pensando/Makefile          |   2 +
 drivers/soc/pensando/kpci_constants.h  |  41 ++
 drivers/soc/pensando/kpcimgr.c         | 900 +++++++++++++++++++++++++
 drivers/soc/pensando/kpcimgr_api.h     | 173 +++++
 drivers/soc/pensando/kpcimgr_sysfs.c   | 277 ++++++++
 6 files changed, 1404 insertions(+)
 create mode 100644 drivers/soc/pensando/kpci_constants.h
 create mode 100644 drivers/soc/pensando/kpcimgr.c
 create mode 100644 drivers/soc/pensando/kpcimgr_api.h
 create mode 100644 drivers/soc/pensando/kpcimgr_sysfs.c

diff --git a/arch/arm64/boot/dts/pensando/elba.dtsi b/arch/arm64/boot/dts/pensando/elba.dtsi
index ec59d762b..9f0d7879a 100644
--- a/arch/arm64/boot/dts/pensando/elba.dtsi
+++ b/arch/arm64/boot/dts/pensando/elba.dtsi
@@ -276,5 +276,16 @@ pcie@307c2480 {
 			       0x0 0x1400 0x0 0x10		/* WDT0 */
 			       0x0 0x20000000 0x0 0x380000>;	/* PXB Base */
 		};
+
+		kpcimgr@20000000 {
+			compatible = "pensando,kpcimgr";
+			msi-parent = <&its 0xf>;
+			shmem-index = <3>;
+			hwmem-index = <2>;
+			reg =  <0x0 0x20000000 0x0 0x00380000   /* PXB Base */
+				0x0 0x61800000 0x0 0x00101000   /* Interrupts */
+				0x0 0xc4000000 0x0 0x01000000   /* HWMEM */
+				0x0 0x0        0x0 0x02000000>; /* SHMEM */
+		};
 	};
 };
diff --git a/drivers/soc/pensando/Makefile b/drivers/soc/pensando/Makefile
index 675e84d1f..5c89a1576 100644
--- a/drivers/soc/pensando/Makefile
+++ b/drivers/soc/pensando/Makefile
@@ -4,9 +4,11 @@
 obj-y += cap_soc.o
 
 CFLAGS_cap_mem.o := -I$(src)
+ccflags-$(CONFIG_PENSANDO_SOC_PCIE) += -DPEN_COMPAT_V2
 
 obj-$(CONFIG_PENSANDO_SOC_CAPMEM) += cap_mem.o
 obj-$(CONFIG_PENSANDO_SOC_PCIE) += cap_pcie.o cap_reboot.o
+obj-$(CONFIG_PENSANDO_SOC_PCIE) += kpcimgr.o kpcimgr_sysfs.o
 obj-$(CONFIG_PENSANDO_SOC_RSTCAUSE) += cap_rstcause.o
 obj-$(CONFIG_PENSANDO_SOC_CRASH) += cap_crash.o
 obj-$(CONFIG_PENSANDO_SOC_BSM) += cap_bsm.o
diff --git a/drivers/soc/pensando/kpci_constants.h b/drivers/soc/pensando/kpci_constants.h
new file mode 100644
index 000000000..602da16a0
--- /dev/null
+++ b/drivers/soc/pensando/kpci_constants.h
@@ -0,0 +1,41 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2021, 2022, Oracle and/or its affiliates.
+ */
+/*
+ * Layout of non-Linux Memory:
+ *  (base address provided in device tree and may change)
+ *  C500 0000  SHMEM segment (pciehw_shmem_t) [0x942440 bytes ~9.25Mb]
+ *  C5F0 0000  kpcimgr state (kstate_t)       [3 * 64k]
+ *  C5F3 0000  relocated code                 [Allow 256k]
+ *  C5F7 0000  available for stack when in nommu mode (64k)
+ *  C5F8 0000  top of stack
+ *  C5FF FFFF  end of 1M allotted range
+ */
+#define SHMEM_KSTATE_OFFSET       0xF00000
+#define SHMEM_KSTATE_SIZE          0x30000
+#define KSTATE_STACK_OFFSET        0x80000
+#define KSTATE_CODE_OFFSET      (SHMEM_KSTATE_OFFSET + SHMEM_KSTATE_SIZE)
+#define KSTATE_CODE_SIZE        (256 * 1024)
+#define KSTATE_MAGIC            0x1743BA1F
+
+/* size of trace data arrays */
+#define DATA_SIZE 100
+#define MSG_BUF_SIZE 32768
+
+/* uart and time related constants */
+#define PEN_UART 0x4800
+#define UART_THR 0
+#define UART_LSR 0x14
+#define DATA_READY 1
+#define OK_TO_WRITE 0x20
+#define UART_THRE_BIT 5
+
+/* phases */
+#define NOMMU 0
+#define NORMAL 1
+#define NUM_PHASES 2
+
+#define MSI_INDIRECT_IDX	0	/* indirect vector */
+#define MSI_NOTIFY_IDX		1	/* notify vector */
+#define MSI_NVECTORS		2
diff --git a/drivers/soc/pensando/kpcimgr.c b/drivers/soc/pensando/kpcimgr.c
new file mode 100644
index 000000000..e8ceb4263
--- /dev/null
+++ b/drivers/soc/pensando/kpcimgr.c
@@ -0,0 +1,900 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Kernel PCIE Manager Infrastructure
+ *
+ * This driver enables the relocation of module code to handle
+ * Pensando/Elba indirect PCIe transactions. The purpose is to allow
+ * code to persist and run during a kexec reboot. The loaded code runs
+ * in physical mode during arm64_relocate_new_kernel and also during
+ * the early boot phase before traditional driver code can run. This
+ * is all to provide extremely low latency response to indirect
+ * transactions, which must be serviced within 200ms.
+ *
+ * Copyright (c) 2021, 2022, Oracle and/or its affiliates.
+ */
+
+#include "kpcimgr_api.h"
+#include "penpcie_dev.h"
+
+MODULE_LICENSE("GPL");
+
+kstate_t *kstate;
+DEFINE_SPINLOCK(kpcimgr_lock);
+static DECLARE_WAIT_QUEUE_HEAD(event_queue);
+
+void wake_up_event_queue(void)
+{
+	wake_up_interruptible(&event_queue);
+}
+
+/*
+ * We need our own memset/memcpy to avoid using
+ * any arm instructions that affect the memory cache.
+ * The memory used for kstate/code/etc is uncached.
+ */
+void *kpci_memset(void *s, int c, size_t n)
+{
+	if (((uintptr_t)s & 0x3) == 0 && (n & 0x3) == 0) {
+		u32 *p;
+		int i;
+
+		c &= 0xff;
+		c = ((c << 0) |
+		     (c << 8) |
+		     (c << 16) |
+		     (c << 24));
+		for (p = s, i = 0; i < n >> 2; i++, p++)
+			*p = c;
+	} else {
+		u8 *p;
+		int i;
+
+		for (p = s, i = 0; i < n; i++, p++)
+			*p = c;
+	}
+
+	return s;
+}
+
+void *kpci_memcpy(void *dst, const void *src, size_t n)
+{
+	u8 *d = dst;
+	const u8 *s = src;
+	int i;
+
+	for (i = 0; i < n; i++)
+		*d++ = *s++;
+
+	return dst;
+}
+
+/*
+ * Normal poll
+ */
+void kpcimgr_normal_poll(void)
+{
+	void (*poll_fn)(kstate_t *, int, int);
+	kstate_t *ks = get_kstate();
+	unsigned long flags;
+
+	spin_lock_irqsave(&kpcimgr_lock, flags);
+	if (ks->valid == KSTATE_MAGIC) {
+		poll_fn = ks->code_base + ks->code_offsets[K_ENTRY_POLL];
+		poll_fn(ks, 0, NORMAL);
+	}
+	spin_unlock_irqrestore(&kpcimgr_lock, flags);
+}
+
+void kpcimgr_start_running(void)
+{
+	kstate_t *ks = get_kstate();
+	void (*init_fn)(kstate_t *ks);
+	unsigned long flags;
+
+	spin_lock_irqsave(&kpcimgr_lock, flags);
+	if (ks->valid == KSTATE_MAGIC) {
+		init_fn = ks->code_base + ks->code_offsets[K_ENTRY_INIT_INTR];
+		ks->running = 1;
+		init_fn(ks);
+	}
+	spin_unlock_irqrestore(&kpcimgr_lock, flags);
+}
+
+void kpcimgr_stop_running(void)
+{
+	kstate_t *ks = get_kstate();
+	void (*shut_fn)(int n);
+	unsigned long flags;
+
+	spin_lock_irqsave(&kpcimgr_lock, flags);
+	if (ks->valid == KSTATE_MAGIC) {
+		shut_fn = ks->code_base + ks->code_offsets[K_ENTRY_SHUT];
+		shut_fn(ks->active_port);
+	}
+	spin_unlock_irqrestore(&kpcimgr_lock, flags);
+
+	ks->running = 0;
+}
+
+/*
+ * Read event(s) from the event queue. Used by pciemgrd to find out
+ * about h/w event notifications that arrived during times when
+ * pciemgrd is not running (ie, during a kexec).
+ *
+ * Standard event queue semantics:
+ *  evq_head = index of slot used for next insertion
+ *  evq_tail = index of slot used for next removal
+ *  queue is empty when head == tail
+ *  queue is full when (head + 1) % queue_size == tail
+ *  queue is nearly full when (head + 2) % queue_size == tail
+ *
+ * Only tail is modified here, and the event handler only
+ * modifies head, so theoretically no race can exist between
+ * queue insertion/removal. The mutex is here only to
+ * cover the case of multiple readers.
+ */
+static ssize_t
+read_kpcimgr(struct file *file, char __user *buf, size_t nbytes, loff_t *ppos)
+{
+	static DEFINE_MUTEX(evq_lock);
+	kstate_t *ks = get_kstate();
+	char localmem[EVENT_SIZE];
+	ssize_t n = 0;
+	int tail;
+
+	mutex_lock(&evq_lock);
+	tail = ks->evq_tail;
+
+	while (nbytes >= EVENT_SIZE && ks->evq_head != tail) {
+		/*
+		 * intermediate copy since we cannot prevent copy_to_user
+		 * from doing cache operations
+		 */
+		kpci_memcpy(localmem, (void *)ks->evq[tail], EVENT_SIZE);
+
+		if (copy_to_user(buf + n, localmem, EVENT_SIZE)) {
+			mutex_unlock(&evq_lock);
+			return -EFAULT;
+		}
+
+		tail = (tail + 1) % EVENT_QUEUE_LENGTH;
+		n = n + EVENT_SIZE;
+		nbytes = nbytes - EVENT_SIZE;
+	}
+	ks->evq_tail = tail;
+	mutex_unlock(&evq_lock);
+
+	return n;
+}
+
+/*
+ * pciemgrd wants to select() on /dev/kpcimgr to discover
+ * if there are events in the event queue.
+ */
+static unsigned int
+poll_kpcimgr(struct file *file, poll_table *wait)
+{
+	kstate_t *ks = get_kstate();
+
+	poll_wait(file, &event_queue, wait);
+	if (ks->evq_head != ks->evq_tail)
+		return POLLIN | POLLRDNORM;
+	else
+		return 0;
+}
+
+static int mmap_kpcimgr(struct file *file, struct vm_area_struct *vma)
+{
+	phys_addr_t offset = (phys_addr_t)vma->vm_pgoff << PAGE_SHIFT;
+	size_t size = vma->vm_end - vma->vm_start;
+	pgprot_t pgprot = vma->vm_page_prot;
+	kstate_t *ks = get_kstate();
+	unsigned long pfn, start;
+	void *pos;
+
+	if (offset + size > ks->shmem_size)
+		return -EINVAL;
+
+	if (ks->shmembase) {
+		pfn = (ks->shmembase + offset) >> PAGE_SHIFT;
+		pgprot = pgprot_device(pgprot);
+
+		if (!(file->f_flags & O_SYNC))
+			return -EINVAL;
+
+		pgprot = pgprot_writecombine(pgprot);
+		vma->vm_page_prot = pgprot;
+		if (remap_pfn_range(vma, vma->vm_start, pfn,
+				    size, vma->vm_page_prot))
+			return -EINVAL;
+	} else {
+		for (start = vma->vm_start, pos = ks->shmemva + offset;
+		     size > 0;
+		     start += PAGE_SIZE, pos += PAGE_SIZE, size -= PAGE_SIZE) {
+			pfn = vmalloc_to_pfn(pos);
+			if (remap_pfn_range(vma, start, pfn,
+					    PAGE_SIZE, vma->vm_page_prot))
+				return -EINVAL;
+		}
+	}
+
+	return 0;
+}
+
+/*
+ * Semantics of open(): if no code is loaded then open fails.
+ */
+static int open_kpcimgr(struct inode *inode, struct file *filp)
+{
+	kstate_t *ks = get_kstate();
+
+	if (ks->valid == KSTATE_MAGIC)
+		return 0;
+	else
+		return -ENODEV;
+}
+
+/*
+ * Examine code and look for calls (BL insn) and data references
+ * (ADRP) to memory addresses outside of the bounds of the module. If
+ * any are found, report them and return an error.
+ */
+int contains_external_refs(struct module *mod, void *code_end)
+{
+	unsigned long start = (unsigned long)mod->core_layout.base;
+	char code_loc[KSYM_SYMBOL_LEN], target_ref[KSYM_SYMBOL_LEN];
+	int insn_count, call_count, adrp_count;
+	unsigned long size, target, insn_addr;
+	s32 offset;
+	u32 insn;
+
+	size = (unsigned long)code_end - start;
+
+	for (insn_addr = start, insn_count = 0, call_count = 0, adrp_count = 0;
+	     insn_addr < start + size;
+	     insn_addr += sizeof(u32)) {
+		if (aarch64_insn_read((void *)insn_addr, &insn)) {
+			pr_err("Failed to read insn @ %lx\n", insn_addr);
+			return 1;
+		}
+		insn_count++;
+
+		if (aarch64_insn_is_bl(insn)) {
+			offset = aarch64_get_branch_offset(insn);
+			target = insn_addr + offset;
+
+			if (within_module(target, mod))
+				continue;
+
+			sprint_symbol(code_loc, insn_addr);
+			sprint_symbol(target_ref, target);
+			pr_err("Found call to %s at %s\n",
+			       target_ref, code_loc);
+
+			call_count++;
+		}
+
+		if (aarch64_insn_is_adrp(insn)) {
+			offset = aarch64_insn_adrp_get_offset(insn);
+			target = (insn_addr & PAGE_MASK) + offset;
+
+			if (within_module(target, mod))
+				continue;
+
+			sprint_symbol(code_loc, insn_addr);
+			sprint_symbol(target_ref, target);
+			pr_err("Found approximate reference to %s at %s\n",
+			       target_ref, code_loc);
+			pr_err(" (Please check object file for exact reference)\n");
+			adrp_count++;
+		}
+	}
+	pr_info("processed %d insns, %d extern calls, %d extern adrps\n",
+		insn_count, call_count, adrp_count);
+
+	if (call_count > 0 || adrp_count > 0)
+		return 1;
+	else
+		return 0;
+}
+
+/*
+ * module_register
+ *
+ * Register module code/data to be used with kpcimgr. If requested, we
+ * relocate module code to "non-linux memory". The struct module
+ * pointer is not quite enough to do this, and we require a pointer
+ * to the end of the module code section. This is because we need to
+ * examine the code for certain instructions, and we don't want to
+ * look beyond the end of the code since that will be data which
+ * might contain values which just look like instructions.
+ *
+ * If the code contains no external references, then we can freely
+ * relocate the code repeatedly without relinking.
+ *
+ * We shut down service and then copy the module in its entirety to
+ * non-linux memory which we have previously mapped executable.
+ *
+ * We can also run with the module code unrelocated, but this is only
+ * for debugging, as it preserves the modules symbols in kallsyms, so
+ * any stack trace will show useful function names instead of raw hex
+ * addresses.
+ *
+ * After the copy, we restart the service if necessary.
+ */
+int kpcimgr_module_register(struct module *mod,
+			    struct kpcimgr_entry_points_t *ep, int relocate)
+{
+	void *code_end = ep->code_end;
+	kstate_t *ks = get_kstate();
+	unsigned long start_addr, iflags;
+	void (*init_fn)(kstate_t *ks);
+	void (*version_fn)(char **);
+	char *mod_buildtime;
+	int i, was_running, nentries;
+
+	start_addr = (unsigned long)mod->core_layout.base;
+
+	if (ep->expected_mgr_version != KPCIMGR_KERNEL_VERSION
+#ifdef PEN_COMPAT_V2
+	    && ep->expected_mgr_version != 2
+#endif
+	   ) {
+		pr_info("KPCIMGR: '%s' expects kernel version %d, incompatible with version %d\n",
+			mod->name, ep->expected_mgr_version, KPCIMGR_KERNEL_VERSION);
+		return -EINVAL;
+	}
+
+	if (contains_external_refs(mod, code_end)) {
+		pr_err("KPCIMGR: relocation failed for '%s'\n", mod->name);
+		return -ENXIO;
+	}
+
+	if (mod->core_layout.size > KSTATE_CODE_SIZE) {
+		pr_err("KPCIMGR: module '%s' too large\n", mod->name);
+		return -EFBIG;
+	}
+
+	was_running = ks->running;
+	if (was_running) {
+		pr_info("%s: kpcimgr has stopped running\n", __func__);
+		kpcimgr_stop_running();
+	}
+	spin_lock_irqsave(&kpcimgr_lock, iflags);
+	ks->valid = 0;
+
+	if (ks->mod) {
+		module_put(ks->mod);
+		ks->mod = NULL;
+		ks->code_base = NULL;
+	}
+
+	if (ks->code_base)
+		module_memfree(ks->code_base);
+
+	if (relocate) {
+		ks->code_base = module_alloc(mod->core_layout.size);
+
+		if (ks->code_base == NULL) {
+			pr_err("KPCIMGR: module_alloc(%x)\n",
+			       mod->core_layout.size);
+			return -ENOMEM;
+		}
+		kpci_memcpy(ks->code_base, mod->core_layout.base,
+			    mod->core_layout.size);
+		flush_icache_range((long)ks->code_base, (long)ks->code_base + mod->core_layout.size);
+		set_memory_x((unsigned long)ks->code_base,
+			     mod->core_layout.size >> PAGE_SHIFT);
+	} else {
+		try_module_get(mod);
+		ks->mod = mod;
+		ks->code_base = mod->core_layout.base;
+	}
+	ks->code_size = mod->core_layout.size;
+
+#ifdef PEN_COMPAT_V2
+	nentries = ep->expected_mgr_version == 2 ? 7 : K_NUM_ENTRIES;
+#else
+	nentries = K_NUM_ENTRIES;
+#endif
+	for (i = 0; i < nentries; i++)
+		ks->code_offsets[i] = (unsigned long)ep->entry_point[i]
+			- start_addr;
+	for (; i < K_NUM_ENTRIES; i++)
+		ks->code_offsets[i] = 0;
+
+	if (ks->code_offsets[K_ENTRY_INIT_FN]) {
+		init_fn = ks->code_base + ks->code_offsets[K_ENTRY_INIT_FN];
+		init_fn(ks);
+	}
+
+	mod_buildtime = "";
+	if (ks->code_offsets[K_ENTRY_GET_VERSION]) {
+		version_fn = ks->code_base + ks->code_offsets[K_ENTRY_GET_VERSION];
+		version_fn(&mod_buildtime);
+	}
+
+	pr_info("KPCIMGR: module '%s: %s', start=%lx, end=%lx, size=%d\n",
+		mod->name, mod_buildtime, start_addr,
+		start_addr + mod->core_layout.size, mod->core_layout.size);
+
+	set_init_state(ks);
+	ks->valid = KSTATE_MAGIC;
+	ks->lib_version_major = ep->lib_version_major;
+	ks->lib_version_minor = ep->lib_version_minor;
+
+	spin_unlock_irqrestore(&kpcimgr_lock, iflags);
+	if (was_running) {
+		kpcimgr_start_running();
+		pr_info("%s: kpcimgr will begin running\n", __func__);
+	} else {
+		reset_stats(ks);
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL(kpcimgr_module_register);
+
+static void unmap_resources(void)
+{
+	kstate_t *ks = get_kstate();
+
+	int i;
+
+	for (i = 0; i < ks->nranges; i++) {
+		if (ks->mem_ranges[i].vaddr)
+			iounmap(ks->mem_ranges[i].vaddr);
+	}
+
+	if (ks->uart_addr)
+		iounmap(ks->uart_addr);
+
+	if (ks->have_persistent_mem) {
+		if (ks->persistent_base)
+			iounmap(ks->persistent_base);
+		if (ks->shmemva)
+			iounmap(ks->shmemva);
+		iounmap(ks);
+	} else {
+		vfree(ks->shmemva);
+		vfree((void *)ks);
+	}
+}
+
+static int map_resources(struct platform_device *pfdev)
+{
+	struct device_node *dn = pfdev->dev.of_node;
+	u32 shmem_idx, hwmem_idx;
+	struct resource res;
+	kstate_t *ks;
+	void *shmem;
+	int i, err;
+
+	err = of_property_read_u32(dn, "hwmem-index", &hwmem_idx);
+	if (err) {
+		pr_err("KPCIMGR: no hwmem-index value found\n");
+		return -ENOMEM;
+	}
+
+	err = of_property_read_u32(dn, "shmem-index", &shmem_idx);
+	if (err) {
+		pr_err("KPCIMGR: no shmem-index value found\n");
+		return -ENOMEM;
+	}
+
+	err = of_address_to_resource(dn, shmem_idx, &res);
+	if (err) {
+		pr_err("KPCIMGR: no resource found for shmem-index=%d\n",
+		       shmem_idx);
+		return -ENOMEM;
+	}
+
+	if (res.start == 0) {
+		/* indicates no persistent memory */
+		pr_info("KPCIMGR: no persistent memory\n");
+		ks = vmalloc(sizeof(kstate_t));
+		if (ks == NULL)
+			return -ENOMEM;
+		memset((void *)ks, 0, sizeof(kstate_t));
+		ks->active_port = -1;
+		ks->have_persistent_mem = 0;
+		shmem = vmalloc(resource_size(&res));
+		if (shmem == NULL) {
+			vfree((void *)ks);
+			return -ENOMEM;
+		}
+		ks->shmembase = 0;
+		ks->shmem_size = resource_size(&res);
+	} else {
+		if (resource_size(&res) > SHMEM_KSTATE_OFFSET) {
+			pr_err("KPCIMGR: shmem size overlaps kstate\n");
+			return -ENODEV;
+		}
+		shmem = ioremap(res.start, resource_size(&res));
+		if (shmem == NULL) {
+			pr_err("KPCIMGR: failed to map shmem\n");
+			return -ENODEV;
+		}
+
+		ks = ioremap(res.start + SHMEM_KSTATE_OFFSET, sizeof(kstate_t));
+		if (ks == NULL) {
+			pr_err("KPCIMGR: failed to map kstate\n");
+			iounmap(shmem);
+			return -ENOMEM;
+		}
+		if (ks->valid != KSTATE_MAGIC) {
+			kpci_memset((void *)ks, 0, sizeof(kstate_t));
+			ks->active_port = -1;
+		}
+
+		ks->have_persistent_mem = 1;
+		ks->shmembase = res.start;
+		ks->shmem_size = resource_size(&res);
+		pr_info("KPCIMGR: kstate mapped %llx at %lx\n",
+			res.start + SHMEM_KSTATE_OFFSET, (long)ks);
+
+		ks->persistent_base = ioremap(res.start + KSTATE_CODE_OFFSET,
+					      KSTATE_CODE_SIZE);
+		if (ks->persistent_base == NULL) {
+			pr_err("KPCIMGR: failed to map shmem code space\n");
+			goto errout;
+		}
+
+		if (ks->valid == KSTATE_MAGIC) {
+			ks->code_base = module_alloc(ks->code_size);
+			if (ks->code_base == NULL) {
+				pr_err("KPCIMGR: module_alloc(%lx) failed\n",
+				       ks->code_size);
+				goto errout;
+			}
+			kpci_memcpy(ks->code_base, ks->persistent_base,
+				    ks->code_size);
+			flush_icache_range((long)ks->code_base, (long)ks->code_base + KSTATE_CODE_SIZE);
+			set_memory_x((unsigned long)ks->code_base,
+				     ks->code_size >> PAGE_SHIFT);
+		}
+	}
+
+	kstate = ks;
+	ks->shmemva = shmem;
+
+	ks->uart_addr = ioremap(PEN_UART, 0x1000);
+	if (ks->uart_addr == NULL) {
+		pr_err("KPCIMGR: failed to map elba uart\n");
+		goto errout;
+	}
+	ks->driver_start_time = read_sysreg(cntvct_el0);
+
+	ks->nranges = 0;
+	for (i = 0; i < NUM_MEMRANGES; i++) {
+		struct mem_range_t *mr = &ks->mem_ranges[ks->nranges];
+
+		if (i == shmem_idx)
+			continue;
+
+		err = of_address_to_resource(dn, i, &res);
+		if (err)
+			break;
+
+		mr->base = res.start;
+		mr->end = res.start + resource_size(&res);
+		mr->vaddr = ioremap(res.start, resource_size(&res));
+		if (IS_ERR(mr->vaddr)) {
+			pr_err(PFX "iomap resource %d failed\n", i);
+			goto errout;
+		}
+		if (i == hwmem_idx)
+			ks->hwmem_idx = ks->nranges;
+		ks->nranges++;
+	}
+	return 0;
+
+ errout:
+	unmap_resources();
+	return -ENOMEM;
+}
+
+/*
+ * ISR for indirect transaction
+ */
+static irqreturn_t kpcimgr_indirect_intr(int irq, void *arg)
+{
+	int (*intr_fn)(kstate_t *, int);
+	kstate_t *ks = (kstate_t *)arg;
+	int port, r = 0;
+
+	spin_lock(&kpcimgr_lock);
+	if (ks->valid == KSTATE_MAGIC) {
+		ks->ind_intr++;
+		intr_fn = ks->code_base +
+			ks->code_offsets[K_ENTRY_INDIRECT_INTR];
+
+		port = ks->active_port;
+		if (port >= 0)
+			r = intr_fn(ks, port);
+	}
+	spin_unlock(&kpcimgr_lock);
+
+	return r ? IRQ_HANDLED : IRQ_NONE;
+}
+
+/*
+ * ISR for notify transaction
+ */
+static irqreturn_t kpcimgr_notify_intr(int irq, void *arg)
+{
+	int (*intr_fn)(kstate_t *, int);
+	kstate_t *ks = (kstate_t *)arg;
+	int port, r = 0;
+
+	spin_lock(&kpcimgr_lock);
+	if (ks->valid == KSTATE_MAGIC) {
+		ks->not_intr++;
+		intr_fn = ks->code_base + ks->code_offsets[K_ENTRY_NOTIFY_INTR];
+
+		port = ks->active_port;
+		if (port >= 0)
+			r = intr_fn(ks, port);
+	}
+	spin_unlock(&kpcimgr_lock);
+
+	return r ? IRQ_HANDLED : IRQ_NONE;
+}
+
+u64 kpcimgr_preg_read(u64 pa)
+{
+	u32 val;
+
+	pciep_regrd32((uint64_t)pa, &val);
+	return (u64)val;
+}
+
+static u64 kpcimgr_upcall(int req, u64 arg1, u64 arg2, u64 arg3)
+{
+	kstate_t *ks = get_kstate();
+
+	if (ks->valid != KSTATE_MAGIC)		/* no code loaded */
+		return 1;
+
+	switch (req) {
+	case WAKE_UP_EVENT_QUEUE:
+		ks->event_intr++;
+		wake_up_event_queue();
+		break;
+	case PRINT_LOG_MSG:
+		printk((char *)arg1); /* KERN_LEVEL provided by arg1 */
+		break;
+	case PREG_READ:
+		return kpcimgr_preg_read(arg1);
+	default:
+		return 1;
+	}
+	return 0;
+}
+
+static void set_msi_msg(struct msi_desc *desc, struct msi_msg *msg)
+{
+	kstate_t *ks = get_kstate();
+	struct msi_info *msi = &ks->msi[desc->msi_index];
+
+	msi->msgaddr = ((u64)msg->address_hi << 32) | msg->address_lo;
+	msi->msgdata = msg->data;
+}
+
+static void free_intrs(struct platform_device *pfdev)
+{
+	kstate_t *ks = get_kstate();
+	struct device *dev = &pfdev->dev;
+
+#if 0
+	for_each_msi_entry(desc, dev)
+		free_irq(desc->irq, (void *)ks);
+#endif
+	free_irq(msi_get_virq(dev, MSI_INDIRECT_IDX), (void *)ks);
+	free_irq(msi_get_virq(dev, MSI_NOTIFY_IDX), (void *)ks);
+	platform_msi_domain_free_irqs(&pfdev->dev);
+}
+
+struct {
+	irqreturn_t (*isr)(int irq, void *arg);
+	char *name;
+} kpcimgr_irq_table[] = {
+	{ kpcimgr_indirect_intr, "kpcimgr-indirect"},
+	{ kpcimgr_notify_intr,   "kpcimgr-notify"  },
+};
+
+static int alloc_intrs(struct platform_device *pfdev)
+{
+	irqreturn_t (*isr)(int irq, void *arg);
+	struct device *dev = &pfdev->dev;
+	kstate_t *ks = get_kstate();
+	char *name;
+	int r;
+
+	r = platform_msi_domain_alloc_irqs(dev, MSI_NVECTORS, set_msi_msg);
+	if (r)
+		return r;
+#if 0
+	for_each_msi_entry(desc, dev) {
+		isr = kpcimgr_irq_table[desc->msi_index].isr;
+		name = kpcimgr_irq_table[desc->msi_index].name;
+		r = devm_request_irq(dev, desc->irq, isr, 0, name, (void *)ks);
+		if (r)
+			goto err_out;
+	}
+#endif
+	r = devm_request_irq(dev, msi_get_virq(dev, MSI_INDIRECT_IDX),
+			kpcimgr_irq_table[MSI_INDIRECT_IDX].isr, 0,
+			kpcimgr_irq_table[MSI_INDIRECT_IDX].name, (void *)ks);
+	if (r)
+		goto err_out;
+	r = devm_request_irq(dev, msi_get_virq(dev, MSI_NOTIFY_IDX),
+			kpcimgr_irq_table[MSI_NOTIFY_IDX].isr, 0,
+			kpcimgr_irq_table[MSI_NOTIFY_IDX].name, (void *)ks);
+	if (r)
+		goto err_out;
+	return 0;
+
+ err_out:
+	free_intrs(pfdev);
+	return r;
+}
+
+/*
+ * Called when a kexec is about to happen
+ */
+static int kpcimgr_notify_reboot(struct notifier_block *this,
+				 unsigned long code,
+				 void *unused)
+{
+	kstate_t *ks = get_kstate();
+	int was_running = ks->running;
+
+	/* stop running regardless of why a reboot is happening */
+	free_intrs(ks->pfdev);
+	if (was_running)
+		kpcimgr_stop_running();
+
+	if (!ks->code_base) {
+		pr_err("KPCIMGR: halting since no code is loaded\n");
+		ks->valid = 0;
+		return NOTIFY_DONE;
+	}
+
+	if (!ks->have_persistent_mem) {
+		pr_err("KPCIMGR: halting since code is not persistent\n");
+		ks->valid = 0;
+		return NOTIFY_DONE;
+	}
+
+	/* relocate code to "persistent" memory */
+	kpci_memcpy(ks->persistent_base, ks->code_base, ks->code_size);
+
+	if (code == SYS_DOWN) {
+		pr_err("KPCIMGR: going down at tick %lld\n",
+		       read_sysreg(cntvct_el0));
+
+		if (was_running)
+			ks->running = 1;
+
+		reset_stats(ks);
+		ks->ncalls = 0;
+		ks->kexec_time = read_sysreg(cntvct_el0);
+	}
+	return NOTIFY_DONE;
+}
+
+/*
+ * Driver Initialization
+ */
+static const struct file_operations __maybe_unused kpcimgr_fops = {
+	.owner          = THIS_MODULE,
+	.read           = read_kpcimgr,
+	.poll           = poll_kpcimgr,
+	.open           = open_kpcimgr,
+	.mmap           = mmap_kpcimgr,
+};
+
+static struct miscdevice kpcimgr_dev = {
+	MISC_DYNAMIC_MINOR,
+	KPCIMGR_NAME,
+	&kpcimgr_fops
+};
+
+static int kpcimgr_probe(struct platform_device *pfdev)
+{
+	kstate_t *ks;
+	int err;
+
+	err = map_resources(pfdev);
+	if (err)
+		goto errout;
+
+	ks = get_kstate();
+	ks->pfdev = pfdev;
+
+	err = alloc_intrs(ks->pfdev);
+	if (err) {
+		pr_err(PFX "alloc intrs: %d\n", err);
+		goto errout_unmap;
+	}
+
+	err = misc_register(&kpcimgr_dev);
+	if (err) {
+		pr_err(PFX "register pciemgr_dev failed: %d\n", err);
+		goto errout_free_intrs;
+	}
+
+	ks->upcall = (void *)kpcimgr_upcall;
+	ks->mod = NULL;
+	if (ks->valid == KSTATE_MAGIC && ks->running) {
+		kpcimgr_start_running();
+		kpcimgr_normal_poll();
+		pr_err("KPCIMGR: initialized and running.\n");
+	}
+	if (ks->have_persistent_mem) {
+		static struct notifier_block kpcimgr_nb = {
+			.notifier_call = kpcimgr_notify_reboot,
+			.next = NULL,
+			.priority = 0,
+		};
+		register_reboot_notifier(&kpcimgr_nb);
+	}
+
+	pr_info("KPCIMGR: kstate mapped at %lx, code at %lx\n",
+		(long)ks, (long)ks->code_base);
+
+	kpcimgr_sysfs_setup(pfdev);
+	return 0;
+
+ errout_free_intrs:
+	free_intrs(pfdev);
+
+ errout_unmap:
+	unmap_resources();
+
+ errout:
+	return err;
+}
+
+static const struct of_device_id kpcimgr_of_match[] = {
+	{ .compatible = "pensando,kpcimgr" },
+	{ /* end of table */ }
+};
+
+static struct platform_driver kpcimgr_driver = {
+	.probe = kpcimgr_probe,
+	.driver = {
+		.name = "pensando-kpcimgr",
+		.owner = THIS_MODULE,
+		.of_match_table = kpcimgr_of_match,
+	},
+};
+builtin_platform_driver(kpcimgr_driver);
+
+/*
+ * Get entry point for pciesvc specific secondary cpu holding pen.
+ * Called from arch/arm64/kernel/smp_spin_table.c
+ * We choose the first cpu to arrive here. They will all try
+ * concurrently, but only one will be hijacked and the rest
+ * will go to their default holding pens.
+ */
+unsigned long kpcimgr_get_entry(unsigned long old_entry, unsigned int cpu)
+{
+	unsigned long (*entry_fn)(unsigned long entry, unsigned int cpu);
+	static DEFINE_SPINLOCK(choose_cpu_lock);
+	kstate_t *ks = get_kstate();
+	unsigned long entry;
+
+	if (ks == NULL || ks->valid != KSTATE_MAGIC ||
+	    !ks->running || !ks->have_persistent_mem)
+		return old_entry;
+
+	entry_fn = ks->code_base + ks->code_offsets[K_ENTRY_HOLDING_PEN];
+
+	spin_lock(&choose_cpu_lock);
+	entry = entry_fn(old_entry, cpu);
+	spin_unlock(&choose_cpu_lock);
+
+	return entry;
+}
diff --git a/drivers/soc/pensando/kpcimgr_api.h b/drivers/soc/pensando/kpcimgr_api.h
new file mode 100644
index 000000000..07c821926
--- /dev/null
+++ b/drivers/soc/pensando/kpcimgr_api.h
@@ -0,0 +1,173 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2021, 2022, Oracle and/or its affiliates.
+ */
+#ifndef __KPCIMGR_API_H__
+#define __KPCIMGR_API_H__
+
+#ifdef __KERNEL__
+#include <linux/miscdevice.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/cdev.h>
+#include <linux/reboot.h>
+#include <linux/poll.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/of_platform.h>
+#include <linux/interrupt.h>
+#include <linux/msi.h>
+#include <linux/mm.h>
+#include <linux/kallsyms.h>
+#include <linux/moduleloader.h>
+#include <linux/set_memory.h>
+#include <asm/cacheflush.h>
+#include <asm/insn.h>
+#endif
+
+#include "kpci_constants.h"
+
+#define K_ENTRY_INIT_INTR 0
+#define K_ENTRY_INIT_POLL 1
+#define K_ENTRY_SHUT 2
+#define K_ENTRY_POLL 3
+#define K_ENTRY_HOLDING_PEN 4
+#define K_ENTRY_INDIRECT_INTR 5
+#define K_ENTRY_NOTIFY_INTR 6
+#define K_ENTRY_INIT_FN 7
+#define K_ENTRY_CMD_READ 8
+#define K_ENTRY_CMD_WRITE 9
+#define K_ENTRY_GET_VERSION 10
+#define K_NUM_ENTRIES 16
+
+struct kpcimgr_entry_points_t {
+	int expected_mgr_version;
+	int lib_version_major;
+	int lib_version_minor;
+	void *code_end;
+	void *entry_point[K_NUM_ENTRIES];
+};
+
+/* upcalls */
+#define WAKE_UP_EVENT_QUEUE 1
+#define PRINT_LOG_MSG 2
+#define PREG_READ 3
+
+/* event queue sizing */
+#define EVENT_QUEUE_LENGTH 1024
+#define EVENT_SIZE 128
+
+/* max command size for sysfs cmd node */
+#define CMD_SIZE 4096
+
+/* max number of memory ranges from device tree */
+#define NUM_MEMRANGES 32
+
+struct kpcimgr_state_t {
+	/* essential state */
+	int valid;
+	int debug;
+	int running;
+	int active_port;
+	int have_persistent_mem;
+	int lib_version_major;
+	int lib_version_minor;
+
+	/* timestamps and general trace data */
+	long kexec_time;
+	long driver_start_time;
+	unsigned long trace_data[NUM_PHASES][DATA_SIZE];
+
+	/* virtual addresses */
+	void *uart_addr;
+	void *code_base;
+	void *persistent_base;
+	void *upcall;
+	void *pfdev;
+	void *shmemva;
+
+	unsigned long shmembase, shmem_size, code_size;
+	struct mem_range_t {
+		unsigned long base, end;
+		void *vaddr;
+	} mem_ranges[NUM_MEMRANGES];
+	int nranges;
+	int hwmem_idx;
+
+	/* interrupt vectors */
+	struct msi_info {
+		unsigned long msgaddr;
+		unsigned int msgdata;
+	} msi[MSI_NVECTORS];
+
+	/* stats for work done */
+	int ind_cfgrd, ind_cfgwr;
+	int ind_memrd, ind_memwr;
+	int ncalls;
+	int ind_intr, not_intr, event_intr;
+
+	int unused1[7];	/* was version=2 code_offsets[], keep evq* compat */
+
+	/* Event queue handling */
+	int evq_head, evq_tail;
+	char evq[EVENT_QUEUE_LENGTH][EVENT_SIZE];
+
+	/* debugging */
+	void *mod;
+	int msg_idx;
+	int cfgval;
+
+	/* offsets into relocated library code */
+	int code_offsets[K_NUM_ENTRIES];
+};
+
+typedef struct kpcimgr_state_t kstate_t;
+_Static_assert(sizeof(kstate_t) < SHMEM_KSTATE_SIZE,
+	       "kstate size insufficient");
+
+/* trace_data[] elements */
+#define FIRST_CALL_TIME 0
+#define FIRST_SEQNUM 1
+#define LAST_SEQNUM 2
+#define TAG 3
+#define PA_BAD_CNT 4
+#define NUM_CHECKS 5
+#define NUM_CALLS 6
+#define NUM_PENDINGS 7
+#define LAST_CALL_TIME 8
+#define EARLY_POLL 9
+#define MAX_DATA 10
+
+#define KPCIMGR_DEV "/dev/kpcimgr"
+#define KPCIMGR_NAME "kpcimgr"
+#define PFX KPCIMGR_NAME ": "
+#define KPCIMGR_KERNEL_VERSION 3
+
+#ifdef __KERNEL__
+int kpcimgr_module_register(struct module *mod,
+			    struct kpcimgr_entry_points_t *ep, int relocate);
+void kpcimgr_start_running(void);
+void kpcimgr_stop_running(void);
+void kpcimgr_sysfs_setup(struct platform_device *pfdev);
+void *kpci_memcpy(void *dst, const void *src, size_t n);
+void wake_up_event_queue(void);
+int aarch64_insn_read(void *addr, u32 *insnp);
+extern spinlock_t kpcimgr_lock;
+
+#define reset_stats(k) \
+	kpci_memset((void *)&(k)->trace_data[0][0], 0, sizeof((k)->trace_data))
+
+static inline void set_init_state(kstate_t *k)
+{
+	k->trace_data[NORMAL][FIRST_CALL_TIME] = 0;
+	k->ncalls = 0;
+}
+
+static inline kstate_t *get_kstate(void)
+{
+	extern kstate_t *kstate;
+	return kstate;
+}
+#endif
+
+#endif
diff --git a/drivers/soc/pensando/kpcimgr_sysfs.c b/drivers/soc/pensando/kpcimgr_sysfs.c
new file mode 100644
index 000000000..fcee544a4
--- /dev/null
+++ b/drivers/soc/pensando/kpcimgr_sysfs.c
@@ -0,0 +1,277 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Kernel PCIE Manager SYSFS functions
+ *
+ * Copyright (c) 2021, 2022, Oracle and/or its affiliates.
+ */
+
+#include "kpcimgr_api.h"
+
+int kpcimgr_active_port;
+
+/* 'valid' read returns value of valid field */
+static ssize_t valid_show(struct device *dev,
+			  struct device_attribute *attr,
+			  char *buf)
+{
+	kstate_t *ks = get_kstate();
+
+	return sprintf(buf, "%x\n", ks->valid);
+}
+
+/* 'valid' write causes invalidation, regardless of value written */
+static ssize_t valid_store(struct device *dev,
+			   struct device_attribute *attr,
+			   const char *buf,
+			   size_t count)
+{
+	kstate_t *ks = get_kstate();
+
+	if (ks->running) {
+		kpcimgr_stop_running();
+		pr_info("%s: kpcimgr has stopped running\n", __func__);
+	}
+	ks->valid = 0;
+	ks->debug = 0;
+	if (ks->mod) {
+		module_put(ks->mod);
+		ks->mod = NULL;
+		ks->code_base = NULL;
+	}
+
+	pr_info("%s: code unloaded\n", __func__);
+	return count;
+}
+
+static ssize_t running_show(struct device *dev,
+			    struct device_attribute *attr,
+			    char *buf)
+{
+	kstate_t *ks = get_kstate();
+
+	return sprintf(buf, "%x\n", ks->running | ks->debug);
+}
+
+static ssize_t running_store(struct device *dev,
+			     struct device_attribute *attr,
+			     const char *buf,
+			     size_t count)
+{
+	kstate_t *ks = get_kstate();
+	ssize_t rc;
+	long val;
+
+	rc = kstrtol(buf, 0, &val);
+	if (rc)
+		return rc;
+
+	if (!ks->valid)
+		return -EINVAL;
+
+	if (val == 0) {
+		if (ks->running) {
+			kpcimgr_stop_running();
+			pr_info("%s: kpcimgr has stopped polling\n", __func__);
+		}
+	} else {
+		if (ks->running) {
+			pr_info("%s: kpcimgr is already running\n", __func__);
+		} else {
+			ks->active_port = ffs(kpcimgr_active_port) - 1;
+			pr_info("%s: kpcimgr will begin running on port %d\n",
+				__func__, ks->active_port);
+			kpcimgr_start_running();
+		}
+		ks->debug = val & 0xfff0;
+	}
+
+	return count;
+}
+
+static ssize_t cfgval_show(struct device *dev,
+			   struct device_attribute *attr,
+			   char *buf)
+{
+	kstate_t *ks = get_kstate();
+
+	return sprintf(buf, "%x\n", ks->cfgval);
+}
+
+static ssize_t cfgval_store(struct device *dev,
+			    struct device_attribute *attr,
+			    const char *buf,
+			    size_t count)
+{
+	kstate_t *ks = get_kstate();
+	ssize_t rc;
+	long val;
+
+	rc = kstrtol(buf, 0, &val);
+	if (rc)
+		return rc;
+
+	if (!ks->valid)
+		return -EINVAL;
+
+	ks->cfgval = val;
+	return count;
+}
+
+static ssize_t lib_version_show(struct device *dev,
+				struct device_attribute *attr,
+				char *buf)
+{
+	kstate_t *ks = get_kstate();
+
+	if (!ks->valid)
+		return -ENODEV;
+
+	return sprintf(buf, "%d.%d\n", ks->lib_version_major,
+		       ks->lib_version_minor);
+}
+
+static ssize_t mgr_version_show(struct device *dev,
+				struct device_attribute *attr,
+				char *buf)
+{
+	return sprintf(buf, "%d\n", KPCIMGR_KERNEL_VERSION);
+}
+
+static ssize_t command_read(struct file *file, struct kobject *kobj,
+			    struct bin_attribute *attr, char *out,
+			    loff_t off, size_t count)
+{
+	int (*cmd_read)(kstate_t *, char *, loff_t, size_t, int *);
+	kstate_t *ks = get_kstate();
+	int ret, success = 0;
+	unsigned long flags;
+
+	if (!ks->valid)
+		return -ENODEV;
+	if (ks->code_offsets[K_ENTRY_CMD_READ]) {
+		cmd_read = ks->code_base + ks->code_offsets[K_ENTRY_CMD_READ];
+		spin_lock_irqsave(&kpcimgr_lock, flags);
+		ret = cmd_read(ks, out, off, count, &success);
+		spin_unlock_irqrestore(&kpcimgr_lock, flags);
+	}
+	if (success)
+		return ret;
+	else
+		return 0;
+}
+
+static ssize_t command_write(struct file *filp, struct kobject *kobj,
+			     struct bin_attribute *bin_attr, char *buf,
+			     loff_t off, size_t count)
+{
+	int (*cmd_write)(kstate_t *, const char *, loff_t, size_t, int *);
+	kstate_t *ks = get_kstate();
+	int ret, success = 0;
+	unsigned long flags;
+
+	if (!ks->valid)
+		return -ENODEV;
+	if (ks->code_offsets[K_ENTRY_CMD_WRITE]) {
+		cmd_write = ks->code_base + ks->code_offsets[K_ENTRY_CMD_WRITE];
+		spin_lock_irqsave(&kpcimgr_lock, flags);
+		ret = cmd_write(ks, buf, off, count, &success);
+		spin_unlock_irqrestore(&kpcimgr_lock, flags);
+	}
+	if (success)
+		return ret;
+	else
+		return count;
+}
+
+/* event queue peek */
+static ssize_t event_queue_read(struct file *file, struct kobject *kobj,
+				struct bin_attribute *attr, char *out,
+				loff_t off, size_t count)
+{
+	kstate_t *ks = get_kstate();
+
+	/* is queue empty? */
+	if (ks->evq_head == ks->evq_tail)
+		return 0;
+
+	kpci_memcpy(out, (void *)ks->evq[ks->evq_tail], EVENT_SIZE);
+	return EVENT_SIZE;
+}
+
+/*
+ * This function is for testing. It injects an event onto the
+ * event queue, simulating an event notification from h/w.
+ */
+static ssize_t event_queue_write(struct file *filp, struct kobject *kobj,
+				 struct bin_attribute *bin_attr, char *buf,
+				 loff_t off, size_t count)
+{
+	kstate_t *ks = get_kstate();
+
+	if (count != EVENT_SIZE)
+		return -EINVAL;
+
+	if ((ks->evq_head + 1) % EVENT_QUEUE_LENGTH == ks->evq_tail)
+		return -ENOSPC;
+
+	kpci_memcpy((void *)ks->evq[ks->evq_head], buf, EVENT_SIZE);
+	ks->evq_head = (ks->evq_head + 1) % EVENT_QUEUE_LENGTH;
+	wake_up_event_queue();
+
+	return EVENT_SIZE;
+}
+
+static ssize_t kstate_read(struct file *file, struct kobject *kobj,
+			   struct bin_attribute *attr, char *out,
+			   loff_t off, size_t count)
+{
+	kstate_t *ks = get_kstate();
+
+	kpci_memcpy(out, (void *)ks + off, count);
+	return count;
+}
+
+static DEVICE_ATTR_RW(valid);
+static DEVICE_ATTR_RW(running);
+static DEVICE_ATTR_RW(cfgval);
+static DEVICE_ATTR_RO(lib_version);
+static DEVICE_ATTR_RO(mgr_version);
+static DEVICE_INT_ATTR(active_port, 0644, kpcimgr_active_port);
+static BIN_ATTR_RO(kstate, sizeof(kstate_t));
+static BIN_ATTR_RW(event_queue, EVENT_SIZE);
+static BIN_ATTR_RW(command, CMD_SIZE);
+
+static struct attribute *dev_attrs[] = {
+	&dev_attr_valid.attr,
+	&dev_attr_running.attr,
+	&dev_attr_cfgval.attr,
+	&dev_attr_active_port.attr.attr,
+	&dev_attr_lib_version.attr,
+	&dev_attr_mgr_version.attr,
+	NULL,
+};
+
+static struct bin_attribute *dev_bin_attrs[] = {
+	&bin_attr_kstate,
+	&bin_attr_event_queue,
+	&bin_attr_command,
+	NULL,
+};
+
+const struct attribute_group kpci_attr_group = {
+	.attrs = dev_attrs,
+	.bin_attrs = dev_bin_attrs,
+};
+
+void kpcimgr_sysfs_setup(struct platform_device *pfdev)
+{
+	if (sysfs_create_group(&pfdev->dev.kobj, &kpci_attr_group)) {
+		pr_err("KPCIMGR:sysfs_create_group failed\n");
+		return;
+	}
+
+	if (sysfs_create_link(kernel_kobj, &pfdev->dev.kobj, "kpcimgr")) {
+		pr_err("KPCIMGR: failed top create sysfs link\n");
+		return;
+	}
+}
-- 
2.39.2

