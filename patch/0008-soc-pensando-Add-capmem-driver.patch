From b4958689ffaafbe3302d16137bc05e3ac15860df Mon Sep 17 00:00:00 2001
From: David Clear <dac2@pensando.io>
Date: Mon, 14 Feb 2022 10:16:54 -0800
Subject: [PATCH 08/30] soc: pensando: Add capmem driver

The capmem driver provides an controlled interface for applications
to map memory (in preference to /dev/mem).

Signed-off-by: David Clear <dac2@pensando.io>
Signed-off-by: Ashwin H <Ashwin.H@amd.com>
---
 arch/arm64/boot/dts/pensando/elba.dtsi |  20 +
 drivers/soc/Makefile                   |   1 +
 drivers/soc/pensando/Kconfig           |  14 +
 drivers/soc/pensando/Makefile          |   6 +
 drivers/soc/pensando/cap_mem.c         | 484 +++++++++++++++++++++++++
 drivers/soc/pensando/cap_tracepoint.h  | 172 +++++++++
 drivers/soc/pensando/capmem_dev.h      |  34 ++
 7 files changed, 731 insertions(+)
 create mode 100644 drivers/soc/pensando/Makefile
 create mode 100644 drivers/soc/pensando/cap_mem.c
 create mode 100644 drivers/soc/pensando/cap_tracepoint.h
 create mode 100644 drivers/soc/pensando/capmem_dev.h

diff --git a/arch/arm64/boot/dts/pensando/elba.dtsi b/arch/arm64/boot/dts/pensando/elba.dtsi
index 5f70de667..400eac0c0 100644
--- a/arch/arm64/boot/dts/pensando/elba.dtsi
+++ b/arch/arm64/boot/dts/pensando/elba.dtsi
@@ -49,6 +49,10 @@
 				IRQ_TYPE_LEVEL_LOW)>;
 	};
 
+	capmem {
+		compatible = "pensando,capmem";
+	};
+
 	soc: soc {
 		compatible = "simple-bus";
 		#address-cells = <2>;
@@ -183,6 +187,22 @@
 			};
 		};
 
+		/*
+		 * Until we  know the interrupt domain following this, we
+		 * are forced to use this is the place where interrupts from
+		 * PCI converge. In the ideal case, we use one domain higher,
+		 * where the PCI-ness has been shed.
+		 */
+		pxc0_intr: interrupt-controller@20102200 {
+			compatible = "pensando,soc-ictlr-csrintr";
+			interrupt-controller;
+			reg = <0x0 0x20102200 0x0 0x4>;
+			#interrupt-cells = <3>;
+			interrupt-parent = <&gic>;
+			interrupts = <GIC_SPI 17 IRQ_TYPE_LEVEL_HIGH>;
+			interrupt-names = "pxc0_intr";
+		};
+
 		emmc: mmc@30440000 {
 			compatible = "pensando,elba-emmc", "cdns,sd4hc";
 			clocks = <&emmc_clk>;
diff --git a/drivers/soc/Makefile b/drivers/soc/Makefile
index 36452bed8..4689b3334 100644
--- a/drivers/soc/Makefile
+++ b/drivers/soc/Makefile
@@ -16,6 +16,7 @@ obj-$(CONFIG_ARCH_IXP4XX)	+= ixp4xx/
 obj-$(CONFIG_SOC_XWAY)		+= lantiq/
 obj-y				+= mediatek/
 obj-y				+= amlogic/
+obj-$(CONFIG_ARCH_PENSANDO)	+= pensando/
 obj-y				+= qcom/
 obj-y				+= renesas/
 obj-$(CONFIG_ARCH_ROCKCHIP)	+= rockchip/
diff --git a/drivers/soc/pensando/Kconfig b/drivers/soc/pensando/Kconfig
index da71e35e9..92c3a12d3 100644
--- a/drivers/soc/pensando/Kconfig
+++ b/drivers/soc/pensando/Kconfig
@@ -8,6 +8,20 @@ config ARCH_PENSANDO_ELBA_SOC
 	help
 	  Support for the Pensando Elba SoC
 
+config PENSANDO_SOC_CAPMEM
+	tristate "/dev/capmem driver for the Pensando SoCs"
+	depends on OF
+	default y
+	help
+	  Support for the Pensando SoC memory driver
+
+config PENSANDO_SOC_CAPMEM_HUGEPAGE
+	tristate "Enable hugepage support in capmem"
+	select TRANSPARENT_HUGEPAGE
+	default n
+	help
+	  Support for Huge pages in Pensando SoC memory driver
+
 endmenu
 
 endif
diff --git a/drivers/soc/pensando/Makefile b/drivers/soc/pensando/Makefile
new file mode 100644
index 000000000..fcfb67425
--- /dev/null
+++ b/drivers/soc/pensando/Makefile
@@ -0,0 +1,6 @@
+#
+# Pensando SoC drivers
+#
+CFLAGS_cap_mem.o := -I$(src)
+
+obj-$(CONFIG_PENSANDO_SOC_CAPMEM) += cap_mem.o
diff --git a/drivers/soc/pensando/cap_mem.c b/drivers/soc/pensando/cap_mem.c
new file mode 100644
index 000000000..5a28df392
--- /dev/null
+++ b/drivers/soc/pensando/cap_mem.c
@@ -0,0 +1,484 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (c) 2018-2022, Pensando Systems Inc.
+ */
+
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/errno.h>
+#include <linux/fs.h>
+#include <linux/module.h>
+#include <linux/miscdevice.h>
+#include <linux/platform_device.h>
+#include <linux/of.h>
+#include <linux/fcntl.h>
+#include <linux/init.h>
+#include <linux/pagemap.h>
+#include <linux/pfn_t.h>
+#include "capmem_dev.h"
+
+#define DSC_MEM_ATTR_COHERENT	0x1	// Memory range is coherent
+
+#define CREATE_TRACE_POINTS
+#include "cap_tracepoint.h"
+
+#define CAPMEM_REGION_ALIGN		PMD_SIZE
+
+/*
+ * Memory range information provided by U-Boot on the kernel commandline:
+ * Syntax:
+ *	start-end:type[,start-end:type]
+ *	    start:  hex start address (no 0x prefix)
+ *	    end:    hex end address (inclusive)
+ *	    type:   address space type: coherent | noncoherent
+ * Eg:
+ *	capmem=c0000000-c3f00000:coherent,c8000000-13fffffff:noncoherent
+ *
+ * Only address ranges specified are allowed to be mapped.
+ */
+static char *ranges;
+#ifdef MODULE
+module_param(ranges, charp, 0);
+#else
+static int __init capmem_setup(char *s)
+{
+	ranges = s;
+	return 0;
+}
+__setup("capmem=", capmem_setup);
+#endif
+
+static struct capmem_range mem_range[CAPMEM_MAX_RANGES];
+static int nmem_ranges;
+
+static int capmem_add_range(uint64_t start, uint64_t len, int type)
+{
+	struct capmem_range *p = &mem_range[nmem_ranges];
+
+	if (nmem_ranges == CAPMEM_MAX_RANGES)
+		return -ENOMEM;
+	p->start = start;
+	p->len = len;
+	p->type = type;
+	++nmem_ranges;
+	return 0;
+}
+
+#ifdef CONFIG_PENSANDO_SOC_CAPMEM_HUGEPAGE
+static vm_fault_t cap_mem_pte_fault(struct vm_fault *vmf)
+{
+	struct vm_area_struct *vma = vmf->vma;
+	phys_addr_t phys;
+	pgoff_t pgoff;
+	vm_fault_t rc;
+
+	trace_cap_mem_pte_fault(vma, vmf);
+
+	pgoff = vmf->pgoff;
+	phys = PFN_PHYS(pgoff);
+
+	trace_cap_mem_vmf_insert_pfn_pte(vma, vmf, phys);
+
+	rc = vmf_insert_pfn(vma, vmf->address, PFN_DOWN(phys));
+	if (rc == -ENOMEM)
+		return VM_FAULT_OOM;
+	if (rc < 0 && rc != -EBUSY)
+		return VM_FAULT_SIGBUS;
+
+	return VM_FAULT_NOPAGE;
+}
+
+static vm_fault_t cap_mem_pmd_fault(struct vm_fault *vmf)
+{
+	unsigned long pmd_addr = vmf->address & PMD_MASK;
+	struct vm_area_struct *vma = vmf->vma;
+	phys_addr_t phys;
+	pgoff_t pgoff;
+	pfn_t pfn;
+
+	trace_cap_mem_pmd_fault(vma, vmf);
+
+	if (pmd_addr < vma->vm_start || (pmd_addr + PMD_SIZE) > vma->vm_end)
+		return VM_FAULT_FALLBACK;
+
+	pgoff = linear_page_index(vma, pmd_addr);
+	phys = PFN_PHYS(pgoff);
+
+	if (!IS_ALIGNED(phys, PMD_SIZE))
+		return VM_FAULT_FALLBACK;
+
+	trace_cap_mem_vmf_insert_pfn_pmd(vma, vmf, phys);
+
+	pfn = phys_to_pfn_t(phys, PFN_DEV|PFN_MAP);
+
+	return vmf_insert_pfn_pmd(vmf, pfn, vmf->flags & FAULT_FLAG_WRITE);
+}
+
+#ifdef CONFIG_HAVE_ARCH_TRANSPARENT_HUGEPAGE_PUD
+static vm_fault_t cap_mem_pud_fault(struct vm_fault *vmf)
+{
+	unsigned long pud_addr = vmf->address & PUD_MASK;
+	struct vm_area_struct *vma = vmf->vma;
+	phys_addr_t phys;
+	pgoff_t pgoff;
+	pfn_t pfn;
+
+	trace_cap_mem_pud_fault(vma, vmf);
+
+	if (pud_addr < vma->vm_start || (pud_addr + PUD_SIZE) > vma->vm_end)
+		return VM_FAULT_FALLBACK;
+
+	pgoff = linear_page_index(vma, pud_addr);
+	phys = PFN_PHYS(pgoff);
+
+	if (!IS_ALIGNED(phys, PUD_SIZE))
+		return VM_FAULT_FALLBACK;
+
+	trace_cap_mem_vmf_insert_pfn_pud(vma, vmf, phys);
+
+	pfn = phys_to_pfn_t(phys, PFN_DEV|PFN_MAP);
+
+	return vmf_insert_pfn_pud(vmf, pfn, vmf->flags & FAULT_FLAG_WRITE);
+}
+#else
+static vm_fault_t cap_mem_pud_fault(struct vm_fault *vmf)
+{
+	return VM_FAULT_FALLBACK;
+}
+#endif /* !CONFIG_HAVE_ARCH_TRANSPARENT_HUGEPAGE_PUD */
+
+static vm_fault_t cap_mem_huge_fault(struct vm_fault *vmf,
+		enum page_entry_size pe_size)
+{
+	vm_fault_t rc;
+
+	trace_cap_mem_fault_enter(vmf->vma, vmf);
+
+	switch (pe_size) {
+	case PE_SIZE_PTE:
+		rc = cap_mem_pte_fault(vmf);
+		break;
+	case PE_SIZE_PMD:
+		rc = cap_mem_pmd_fault(vmf);
+		break;
+	case PE_SIZE_PUD:
+		rc = cap_mem_pud_fault(vmf);
+		break;
+	default:
+		rc = VM_FAULT_SIGBUS;
+	}
+
+	trace_cap_mem_fault_exit(vmf->vma, vmf);
+
+	return rc;
+}
+
+static vm_fault_t cap_mem_fault(struct vm_fault *vmf)
+{
+	return cap_mem_huge_fault(vmf, PE_SIZE_PTE);
+}
+
+static int cap_mem_split(struct vm_area_struct *vma, unsigned long addr)
+{
+	return -EINVAL;
+}
+
+static const struct vm_operations_struct cap_mem_vm_ops = {
+	.fault = cap_mem_fault,
+	.huge_fault = cap_mem_huge_fault,
+	.split = cap_mem_split,
+};
+
+static unsigned long cap_mem_get_unmapped_area(struct file *filp,
+		unsigned long addr, unsigned long len, unsigned long pgoff,
+		unsigned long flags)
+{
+	unsigned long off, len_align, addr_align, align;
+
+	align = PAGE_SIZE;
+	off = pgoff << PAGE_SHIFT;
+
+	if (len >= PMD_SIZE && IS_ALIGNED(off, PMD_SIZE))
+		align = PMD_SIZE;
+
+#ifdef CONFIG_HAVE_ARCH_TRANSPARENT_HUGEPAGE_PUD
+	if (len >= PUD_SIZE && IS_ALIGNED(off, PUD_SIZE))
+		align = PUD_SIZE;
+#endif
+
+	trace_cap_mem_get_unmapped_area_enter(addr, len, pgoff, align);
+
+	if (align == PAGE_SIZE)
+		goto out;
+
+	len_align = len + align;
+
+	addr = current->mm->get_unmapped_area(filp, addr, len_align, pgoff, flags);
+	if (!IS_ERR_VALUE(addr)) {
+		addr_align = round_up(addr, align);
+		trace_cap_mem_get_unmapped_area_exit(addr_align, len_align, pgoff, align);
+		return addr_align;
+	}
+
+out:
+	addr = current->mm->get_unmapped_area(filp, addr, len, pgoff, flags);
+	trace_cap_mem_get_unmapped_area_exit(addr, len, pgoff, align);
+	return addr;
+}
+#endif
+
+static int cap_mem_mmap(struct file *file, struct vm_area_struct *vma)
+{
+	size_t size = vma->vm_end - vma->vm_start;
+	phys_addr_t p_start = (phys_addr_t)vma->vm_pgoff << PAGE_SHIFT;
+	phys_addr_t p_end = p_start + size - 1;
+	pgprot_t pgprot = vma->vm_page_prot;
+	int i;
+
+	// range cannot wrap
+	if (p_end <= p_start)
+		return -EINVAL;
+
+	// must be MAP_SHARED
+	if (!(vma->vm_flags & VM_MAYSHARE))
+		return -EINVAL;
+
+	// find permitted range
+	for (i = 0; i < nmem_ranges; i++)
+		if (p_start >= mem_range[i].start &&
+		    p_end < (mem_range[i].start + mem_range[i].len))
+			break;
+	if (i == nmem_ranges)
+		return -EPERM;
+
+	switch (mem_range[i].type) {
+	case CAPMEM_TYPE_DEVICE:
+		/* register space must be device-mapped */
+		pgprot = pgprot_device(pgprot);
+		vma->vm_flags |= VM_IO;
+		break;
+
+	case CAPMEM_TYPE_NONCOHERENT:
+		/*
+		 * An inner shareable cached mapping on a noncoherence range
+		 * is invalid, so only accept non-cached mapping requests.
+		 */
+		if (!(file->f_flags & O_SYNC))
+			return -EINVAL;
+		pgprot = pgprot_writecombine(pgprot);
+		break;
+
+	default:
+		// CAPMEM_TYPE_COHERENT - default inner shareable mapping
+		break;
+	}
+
+	/*
+	 * Clear the RDONLY bit and set the DIRTY bit to bypass the
+	 * kernel's clean/dirty page tracking, which uses a page fault on
+	 * first write behavior, which is undesirable for performance.
+	 */
+	if (vma->vm_flags & VM_WRITE)
+		pgprot = __pgprot_modify(pgprot, PTE_RDONLY, PTE_DIRTY);
+
+	vma->vm_page_prot = pgprot;
+
+#ifdef CONFIG_PENSANDO_SOC_CAPMEM_HUGEPAGE
+	vma->vm_ops = &cap_mem_vm_ops;
+	vma->vm_flags |= VM_PFNMAP | VM_HUGEPAGE | VM_DONTEXPAND | VM_DONTDUMP;
+#else
+	/* Remap-pfn-range will mark the range VM_IO */
+	if (remap_pfn_range(vma,
+			    vma->vm_start,
+			    vma->vm_pgoff,
+			    size,
+			    vma->vm_page_prot)) {
+		return -EAGAIN;
+	}
+#endif
+
+	return 0;
+}
+
+static long cap_mem_unlocked_ioctl(struct file *file,
+		unsigned int cmd, unsigned long arg)
+{
+	void __user *p = (void __user *)arg;
+	struct capmem_range __user *rp;
+	struct capmem_ranges_args gr;
+	int i;
+
+	switch (cmd) {
+	case CAPMEM_GET_NRANGES:
+		return put_user(nmem_ranges, (int __user *)p);
+
+	case CAPMEM_GET_RANGES:
+		if (copy_from_user(&gr, p, sizeof(gr)))
+			return -EFAULT;
+		rp = (struct capmem_range __user *)gr.range;
+		for (i = 0; i < gr.nranges; i++) {
+			if (i >= nmem_ranges)
+				return i;
+			if (copy_to_user(rp, &mem_range[i], sizeof(*rp)))
+				return -EFAULT;
+			++rp;
+		}
+		return i;
+
+	default:
+		return -ENOTTY;
+	}
+}
+
+const struct file_operations cap_mem_fops = {
+	.owner		= THIS_MODULE,
+	.mmap		= cap_mem_mmap,
+	.unlocked_ioctl	= cap_mem_unlocked_ioctl,
+#ifdef CONFIG_PENSANDO_SOC_CAPMEM_HUGEPAGE
+	.get_unmapped_area = cap_mem_get_unmapped_area,
+#endif
+};
+
+static struct miscdevice cap_mem_dev = {
+	MISC_DYNAMIC_MINOR,
+	CAPMEM_NAME,
+	&cap_mem_fops
+};
+
+static int __init parse_memory_ranges(struct platform_device *pdev, char *s)
+{
+	uint64_t start, end, len;
+	char *p, *q;
+	int r, type;
+
+	if (!s)
+		return 0;
+
+	while ((p = strsep(&s, ",")) != NULL) {
+		if (nmem_ranges == CAPMEM_MAX_RANGES) {
+			dev_err(&pdev->dev, "too many ranges\n");
+			return -ENODEV;
+		}
+		q = strchr(p, ':');
+		if (!q)
+			goto syntax;
+		*q++ = '\0';
+		if (sscanf(p, "%llx-%llx", &start, &end) != 2)
+			goto syntax;
+		if (end <= start)
+			goto syntax;
+		if (strcmp(q, "coherent") == 0)
+			type = CAPMEM_TYPE_COHERENT;
+		else if (strcmp(q, "noncoherent") == 0)
+			type = CAPMEM_TYPE_NONCOHERENT;
+		else
+			goto syntax;
+		len = end - start + 1;
+		r = capmem_add_range(start, len, type);
+		if (r)
+			return r;
+	}
+	return 0;
+syntax:
+	dev_err(&pdev->dev, "invalid range syntax\n");
+	return -EINVAL;
+}
+
+/*
+ * Device space is mapped out here.
+ */
+static const struct {
+	uint64_t start;
+	uint64_t len;
+} init_device_ranges[] = {
+	{ 0x00200000, 0x6fe00000 }, // 00200000...6fffffff
+};
+
+static void load_static_entries(void)
+{
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(init_device_ranges); i++) {
+		capmem_add_range(init_device_ranges[i].start,
+				 init_device_ranges[i].len,
+				 CAPMEM_TYPE_DEVICE);
+	}
+}
+
+/*
+ * Load ranges from device-tree (installed by u-boot):
+ * The pensando,capmem-ranges parameter is a table of 5 words per row.
+ * The table format is:
+ *	<start_hi start_lo size_hi size_lo attr>
+ *	attr is { unused:30, bypass:1, coherent:1 }
+ */
+static int load_of_ranges(struct platform_device *pdev)
+{
+	u32 entries[CAPMEM_MAX_RANGES][5];
+	int r, n, i, type;
+	u64 start, len;
+
+	n = of_property_read_variable_u32_array(pdev->dev.of_node,
+		"pensando,capmem-ranges", (u32 *)entries,
+		0, sizeof (entries) / sizeof (u32));
+	if (n < 0) {
+		return -ENOENT;
+	}
+	if (n % 5 != 0) {
+		dev_err(&pdev->dev, "of pensando,capmem-ranges invalid\n");
+		return -ENODEV;
+	}
+	n /= 5;
+	for (i = 0; i < n; i++) {
+		type = (entries[i][4] & DSC_MEM_ATTR_COHERENT) ?
+			CAPMEM_TYPE_COHERENT : CAPMEM_TYPE_NONCOHERENT;
+		start = ((u64)entries[i][0] << 32) | entries[i][1];
+		len   = ((u64)entries[i][2] << 32) | entries[i][3];
+		r = capmem_add_range(start, len, type);
+		if (r)
+			return r;
+	}
+	return 0;
+}
+
+static int capmem_probe(struct platform_device *pdev)
+{
+	int r;
+	
+	dev_info(&pdev->dev, "Loading capmem driver\n");
+	load_static_entries();
+	r = load_of_ranges(pdev);
+	if (r == -ENOENT) {
+		/* fallback to the capmem= variable */
+		r = parse_memory_ranges(pdev, ranges);
+		if (r)
+			return r;
+	}
+	return misc_register(&cap_mem_dev);
+}
+
+static int capmem_remove(struct platform_device *pdev)
+{
+	dev_info(&pdev->dev, "Unloading capmem driver\n");
+	misc_deregister(&cap_mem_dev);
+	return 0;
+}
+
+static struct of_device_id capmem_of_match[] = {
+	{ .compatible = "pensando,capmem" },
+	{ /* end of table */ }
+};
+
+static struct platform_driver capmem_driver = {
+	.probe = capmem_probe,
+	.remove = capmem_remove,
+	.driver = {
+		.name = "capmem",
+		.owner = THIS_MODULE,
+		.of_match_table = capmem_of_match,
+	},
+};
+
+module_platform_driver(capmem_driver);
+MODULE_DESCRIPTION("Pensando SoC Memory Driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/soc/pensando/cap_tracepoint.h b/drivers/soc/pensando/cap_tracepoint.h
new file mode 100644
index 000000000..2fbdde703
--- /dev/null
+++ b/drivers/soc/pensando/cap_tracepoint.h
@@ -0,0 +1,172 @@
+/*
+ * Copyright (c) 2021, Pensando Systems Inc.
+ */
+
+#undef TRACE_SYSTEM
+#define TRACE_SYSTEM pensando
+
+#if !defined(_CAP_TRACEPOINT_H_) || defined(TRACE_HEADER_MULTI_READ)
+#define _CAP_TRACEPOINT_H_
+
+#include <linux/tracepoint.h>
+#include <linux/mm_types.h>
+
+DECLARE_EVENT_CLASS(cap_mem_fault,
+
+    TP_PROTO(struct vm_area_struct *vma, struct vm_fault *vmf),
+
+    TP_ARGS(vma, vmf),
+
+    TP_STRUCT__entry(
+        __field(unsigned long, vm_start)
+        __field(unsigned long, vm_end)
+        __field(unsigned long, va)
+        __field(unsigned long, pa)
+    ),
+
+    TP_fast_assign(
+        __entry->vm_start = vma->vm_start;
+        __entry->vm_end = vma->vm_end;
+        __entry->va = vmf->address;
+        __entry->pa = vmf->pgoff << PAGE_SHIFT;
+    ),
+
+    TP_printk("vm_start 0x%lx vm_end 0x%lx va 0x%lx pa 0x%lx",
+        __entry->vm_start,
+        __entry->vm_end,
+        __entry->va,
+        __entry->pa)
+);
+
+DEFINE_EVENT(cap_mem_fault, cap_mem_fault_enter,
+
+    TP_PROTO(struct vm_area_struct *vma, struct vm_fault *vmf),
+
+    TP_ARGS(vma, vmf)
+);
+
+DEFINE_EVENT(cap_mem_fault, cap_mem_fault_exit,
+
+    TP_PROTO(struct vm_area_struct *vma, struct vm_fault *vmf),
+
+    TP_ARGS(vma, vmf)
+);
+
+DEFINE_EVENT(cap_mem_fault, cap_mem_pte_fault,
+
+    TP_PROTO(struct vm_area_struct *vma, struct vm_fault *vmf),
+
+    TP_ARGS(vma, vmf)
+);
+
+DEFINE_EVENT(cap_mem_fault, cap_mem_pmd_fault,
+
+    TP_PROTO(struct vm_area_struct *vma, struct vm_fault *vmf),
+
+    TP_ARGS(vma, vmf)
+);
+
+DEFINE_EVENT(cap_mem_fault, cap_mem_pud_fault,
+
+    TP_PROTO(struct vm_area_struct *vma, struct vm_fault *vmf),
+
+    TP_ARGS(vma, vmf)
+);
+
+DECLARE_EVENT_CLASS(cap_mem_get_unmapped_area,
+
+    TP_PROTO(unsigned long va, unsigned long len, unsigned long pgoff, unsigned long align),
+
+    TP_ARGS(va, len, pgoff, align),
+
+    TP_STRUCT__entry(
+        __field(unsigned long, va)
+        __field(unsigned long, len)
+        __field(unsigned long, pa)
+        __field(unsigned long, align)
+    ),
+
+    TP_fast_assign(
+        __entry->va = va;
+        __entry->len = len;
+        __entry->pa = pgoff << PAGE_SHIFT;
+        __entry->align = align;
+    ),
+
+    TP_printk("vm_start 0x%lx vm_end 0x%lx pa 0x%lx align 0x%lx",
+        __entry->va,
+        __entry->va + __entry->len,
+        __entry->pa,
+        __entry->align
+    )
+);
+
+DEFINE_EVENT(cap_mem_get_unmapped_area, cap_mem_get_unmapped_area_enter,
+
+    TP_PROTO(unsigned long va, unsigned long len, unsigned long pgoff, unsigned long align),
+
+    TP_ARGS(va, len, pgoff, align)
+);
+
+DEFINE_EVENT(cap_mem_get_unmapped_area, cap_mem_get_unmapped_area_exit,
+
+    TP_PROTO(unsigned long va, unsigned long len, unsigned long pgoff, unsigned long align),
+
+    TP_ARGS(va, len, pgoff, align)
+);
+
+DECLARE_EVENT_CLASS(cap_mem_vmf_insert_pfn,
+
+    TP_PROTO(struct vm_area_struct *vma, struct vm_fault *vmf, unsigned long pa),
+
+    TP_ARGS(vma, vmf, pa),
+
+    TP_STRUCT__entry(
+        __field(unsigned long, vm_start)
+        __field(unsigned long, vm_end)
+        __field(unsigned long, va)
+        __field(unsigned long, pa)
+    ),
+
+    TP_fast_assign(
+        __entry->vm_start = vma->vm_start;
+        __entry->vm_end = vma->vm_end;
+        __entry->va = vmf->address;
+        __entry->pa = pa;
+    ),
+
+    TP_printk("vm_start 0x%lx vm_end 0x%lx va 0x%lx pa 0x%lx",
+        __entry->vm_start,
+        __entry->vm_end,
+        __entry->va,
+        __entry->pa)
+);
+
+DEFINE_EVENT(cap_mem_vmf_insert_pfn, cap_mem_vmf_insert_pfn_pte,
+
+    TP_PROTO(struct vm_area_struct *vma, struct vm_fault *vmf, unsigned long pa),
+
+    TP_ARGS(vma, vmf, pa)
+);
+
+DEFINE_EVENT(cap_mem_vmf_insert_pfn, cap_mem_vmf_insert_pfn_pmd,
+
+    TP_PROTO(struct vm_area_struct *vma, struct vm_fault *vmf, unsigned long pa),
+
+    TP_ARGS(vma, vmf, pa)
+);
+
+DEFINE_EVENT(cap_mem_vmf_insert_pfn, cap_mem_vmf_insert_pfn_pud,
+
+    TP_PROTO(struct vm_area_struct *vma, struct vm_fault *vmf, unsigned long pa),
+
+    TP_ARGS(vma, vmf, pa)
+);
+
+#endif  /* !defined(_CAP_TRACEPOINT_H_) || defined(TRACE_HEADER_MULTI_READ) */
+
+#undef TRACE_INCLUDE_PATH
+#undef TRACE_INCLUDE_FILE
+#define TRACE_INCLUDE_PATH .
+#define TRACE_INCLUDE_FILE cap_tracepoint
+#include <trace/define_trace.h>
diff --git a/drivers/soc/pensando/capmem_dev.h b/drivers/soc/pensando/capmem_dev.h
new file mode 100644
index 000000000..ac8547ee1
--- /dev/null
+++ b/drivers/soc/pensando/capmem_dev.h
@@ -0,0 +1,34 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018-2021, Pensando Systems Inc.
+ */
+
+#ifndef __CAPMEM_H__
+#define __CAPMEM_H__
+
+#define CAPMEM_NAME		"capmem"
+#define CAPMEM_DEV		"/dev/capmem"
+#define CAPMEM_IOCTL_NUM	0xcc
+
+struct capmem_range {
+	uint64_t	start;
+	uint64_t	len;
+	int		type;
+};
+enum {
+	CAPMEM_TYPE_DEVICE,
+	CAPMEM_TYPE_COHERENT,
+	CAPMEM_TYPE_NONCOHERENT
+};
+
+struct capmem_ranges_args {
+	struct capmem_range *range;
+	int nranges;
+};
+
+#define CAPMEM_MAX_RANGES	64
+
+#define CAPMEM_GET_NRANGES	_IOR(CAPMEM_IOCTL_NUM, 1, int)
+#define CAPMEM_GET_RANGES	_IOWR(CAPMEM_IOCTL_NUM, 2, struct capmem_ranges_args)
+
+#endif
-- 
2.17.1

